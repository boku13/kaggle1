{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = train.iloc[:, :-1] , train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 26) (4800,)\n",
      "        x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
      "0 -0.789364 -1.434296  0.324867 -1.089570 -3.186751 -1.915492 -1.985052   \n",
      "1  1.698561 -0.530175  0.756504 -0.849795  0.738859  4.321680  3.322877   \n",
      "2  2.480805 -2.933747  1.407295 -0.356059  1.179147 -4.181063 -4.177118   \n",
      "3  1.457755 -0.106902 -0.852411  1.175998  6.619029  2.156072 -0.777952   \n",
      "4  1.427555  0.649282  0.254497 -1.064585  0.303576 -4.545240  4.577316   \n",
      "\n",
      "        x_7       x_8        x_9  ...      x_16      x_17      x_18      x_19  \\\n",
      "0 -5.109614 -1.776943 -10.228432  ... -0.868734 -1.145350 -1.157258 -4.935825   \n",
      "1 -4.769473 -1.148654  -0.623213  ... -2.094125  1.077191 -3.360013 -7.324134   \n",
      "2 -2.854105 -0.223620  -2.034928  ... -1.735243 -3.219309 -0.026445 -8.659095   \n",
      "3  5.031490  0.476906   3.009128  ...  2.225405  4.263037 -0.784668  5.115430   \n",
      "4 -5.233015 -1.007334   0.511030  ... -0.103665  3.363232 -1.767302 -3.108375   \n",
      "\n",
      "       x_20      x_21      x_22      x_23      x_24      x_25  \n",
      "0  1.567903  1.691138 -2.914742  0.713525  1.703421 -0.222027  \n",
      "1  1.074675 -0.984185 -1.361525  2.444832 -1.497029  1.096920  \n",
      "2 -0.152213  0.685907  0.442014  1.818607  2.793273  0.072918  \n",
      "3  1.010681 -0.641215 -6.322318 -0.806044  0.699570  0.260674  \n",
      "4 -1.916984 -0.423236  0.631079 -3.378547 -4.165684  0.967436  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    2.0\n",
      "3    2.0\n",
      "4    2.0\n",
      "Name: labels, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_labels.shape)\n",
    "print(train_features.head()) \n",
    "print(train_labels.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 108 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n",
      "Weighted F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Grid search with F1-score as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid,\n",
    "                           cv=10, n_jobs=-1, verbose=2, scoring='f1_weighted')\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predictions on the test set using the best model\n",
    "y_pred = grid_search.predict(train_features)\n",
    "\n",
    "# Calculate F1-score on the test set\n",
    "f1 = f1_score(train_labels, y_pred, average='weighted')\n",
    "print(\"Weighted F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID       x_0       x_1       x_2       x_3       x_4       x_5       x_6  \\\n",
      "0   1 -0.230293 -3.466028  1.511166  0.740295  3.696918 -2.578689  2.263205   \n",
      "1   2 -0.589310  2.695952 -0.447133  1.742419 -3.912262  7.050236 -2.624268   \n",
      "2   3  2.070704 -1.921016  1.352349  1.948624 -1.549088 -0.623295 -0.013214   \n",
      "3   4  0.130017  2.225700 -0.504748 -0.401777  2.244243  4.770526  1.789050   \n",
      "4   5 -1.718615  0.253217 -0.539986  0.261817  0.246253 -0.502865 -1.190270   \n",
      "\n",
      "        x_7       x_8  ...      x_16      x_17      x_18      x_19      x_20  \\\n",
      "0 -0.126368  1.207075  ... -0.717038 -2.280132 -4.019121  4.175089 -2.939001   \n",
      "1  2.292610 -0.640342  ... -3.313892 -7.084135 -0.161589 -3.913306 -3.592095   \n",
      "2  4.281549 -0.569961  ...  1.295106  0.363587  2.207610  4.304411 -1.301508   \n",
      "3 -1.553924  1.116070  ...  8.556711 -5.356854  2.574727  6.959246  0.220325   \n",
      "4 -1.416252 -1.735776  ... -4.632323 -1.219645  2.092873 -2.675771 -4.998719   \n",
      "\n",
      "       x_21      x_22      x_23      x_24      x_25  \n",
      "0  0.690836 -1.537785  0.523352 -0.287075 -0.033105  \n",
      "1 -2.974472  2.576795 -1.702104  2.209905  0.618079  \n",
      "2 -3.051108  1.138168 -2.822654 -1.628571 -0.441178  \n",
      "3  0.344151  3.047017  1.398412 -0.284969 -0.424696  \n",
      "4  1.639839 -1.230900  2.967112  0.752419 -0.589382  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_labels = grid_search.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved.\n"
     ]
    }
   ],
   "source": [
    "test_pred_df = pd.DataFrame({'Predicted_Labels': grid_search_labels})\n",
    "\n",
    "# Assuming test_features has an 'ID' column for each test sample\n",
    "# If not, you can generate an ID column or use any other unique identifier for each sample\n",
    "test_pred_df['ID'] = test['ID']  # Assuming 'ID' is the column name for the sample ID\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "test_pred_df.to_csv('grid_search.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
